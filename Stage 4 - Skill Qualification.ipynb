{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\Anaconda3\\envs\\tensorflowCPU\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "import operator\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "# from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a json file\n",
    "def open_file(fname):\n",
    "    with open(fname) as jsonfile:\n",
    "            resumes = json.load(jsonfile)\n",
    "    return resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arr_by_skills(resumes):\n",
    "    job_desc=[]\n",
    "    c=0\n",
    "    #     print(puesto)\n",
    "    skill=\"\"\n",
    "    for skills in resumes:\n",
    "        skill=skill+\" \"+skills['skill_name']+\"\\n\"#.replace(\" \",\"_\")\n",
    "    skill=skill.lower()\n",
    "    #     print(skill)\n",
    "    #         cat=skills['skill_category']\n",
    "    if len(skill)>0:\n",
    "        job_desc.append(skill)\n",
    "        c=c+1\n",
    "    return job_desc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence tokenization \n",
    "def token_separation(sDescription=\"\",splitted=True,bSentence=False,bStopwords=False):\n",
    "    \n",
    "    sentenceTkn = []\n",
    "    \n",
    "    #Use of stopwords\n",
    "    stoplist = []\n",
    "    if bStopwords:\n",
    "        stoplist = list(set(stopwords.words('english')))\n",
    "        stoplist.extend([\"–\",\"/\",\"&\",\".\",\"$\",\"(\",\")\",\"!\",\"?\",\";\",\":\",\"'\",\",\",\"“\",\"”\",\"’\"])\n",
    "    \n",
    "    #Convert Description to sentence and Tokenization of words\n",
    "    tnzr = nltk.tokenize\n",
    "    if bSentence:\n",
    "        sDescription=sDescription.replace(\"\\\\n\",\"\\n\").replace(\" \\n \",\"\\n\").replace(\" \\n\",\"\\n\").replace(\"\\n \",\"\\n\").replace(\"\\n\",\".\\n<sen>\").replace(\"..\\n\",\".\\n\")\n",
    "        sentences = sent_tokenize(sDescription)\n",
    "        for sen in sentences:\n",
    "            tnkstr= tnzr.word_tokenize(sen.replace(\"<sen>\",\"\"))\n",
    "            \n",
    "            i_offset = 0\n",
    "            for i, t in enumerate(tnkstr):\n",
    "                i -= i_offset\n",
    "                if t == '#' and i > 0:\n",
    "                    left = tnkstr[:i-1]\n",
    "                    joined = [tnkstr[i - 1] + t]\n",
    "                    right = tnkstr[i + 1:]\n",
    "                    tnkstr = left + joined + right\n",
    "                    i_offset += 1\n",
    "    \n",
    "            lSenTkn=[word for word in tnkstr if (word not in stoplist)]\n",
    "            if len(lSenTkn)>0:\n",
    "                if splitted:\n",
    "                    sentenceTkn.append(lSenTkn)\n",
    "                else:\n",
    "                    sentenceTkn.extend(lSenTkn)\n",
    "    else:\n",
    "        sentences = sDescription\n",
    "        tnkstr= tnzr.word_tokenize(sentences)   \n",
    "        sentenceTkn = [word for word in tnkstr if (word not in stoplist)]\n",
    "\n",
    "    return sentenceTkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infering sentences\n",
    "def infer_doc2vec(model_name,jobs_labeled):\n",
    "    model = model_name\n",
    "\n",
    "    lbl=[]\n",
    "    emb=[]\n",
    "    for job in jobs_labeled:\n",
    "        model.random.seed(0)\n",
    "        vecjob = model.infer_vector(doc_words=job)#, steps=20, alpha=0.025)\n",
    "        emb.append(vecjob)\n",
    "    \n",
    "    docs_emb = {\"Labels\": lbl\n",
    "               ,\"Embedding\": np.array(emb)}\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(v1, v2):\n",
    "    return sum(map(operator.mul, v1, v2))\n",
    "\n",
    "def simil_cos(v1, v2):\n",
    "    prod = dot_product(v1, v2)\n",
    "    len1 = math.sqrt(dot_product(v1, v1))\n",
    "    len2 = math.sqrt(dot_product(v2, v2))\n",
    "    return prod / (len1 * len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClusterQualified(JobId,dPath,LinkedInEmb,model):\n",
    "    Label = CatId2Job[JobId]\n",
    "    print(\"Job Predicted: {}\".format(Label))\n",
    "    pathJob = os.path.join(dPath,\"CompletedPreprocessing/\"+Label.replace(\" \",\"_\"))\n",
    "    \n",
    "    fnameSkills = os.path.join(pathJob,\"ClusterSkillDict_{}.p\".format(Label.replace(\" \",\"\")))\n",
    "    fnameSum = os.path.join(pathJob,\"ClusterSkillSummaryDict_{}.p\".format(Label.replace(\" \",\"\")))\n",
    "    \n",
    "    OverviewedSkills = pd.DataFrame.from_dict(pickle.load(open( fnameSkills, \"rb\" ) ))\n",
    "    SumSkill = pd.DataFrame.from_dict(pickle.load(open( fnameSum, \"rb\" ) ))\n",
    "\n",
    "    qClust=[]\n",
    "    mainclusters=SumSkill['Cluster Label'].values\n",
    "    for n,lsk in enumerate(LinkedInEmb):\n",
    "        for mc in mainclusters:\n",
    "            arrSkill=OverviewedSkills[OverviewedSkills['Cluster']==mc].values\n",
    "            for dfs in arrSkill:\n",
    "                emb=infer_doc2vec(model,token_separation(dfs[1],bSentence=True,bStopwords=True))\n",
    "    #         print(emb)\n",
    "                sim = simil_cos(np.array(lsk),emb[0])\n",
    "                if sim > 0.95:\n",
    "                    qClust.append(dfs[0])\n",
    "                    break;\n",
    "    lqClust= list(set(qClust))\n",
    "    \n",
    "    #To get the Qualified skills by the profile received\n",
    "    QualSkills = SumSkill[SumSkill['Cluster Label'].isin(lqClust)][['Category','Skill']]\n",
    "    NeededSkills = SumSkill[~SumSkill['Cluster Label'].isin(lqClust)][['Category','Skill']]\n",
    "    print (\"\\n##################  Skills Qualified  #####################\")\n",
    "    print(QualSkills)\n",
    "    print (\"\\n##################  Nedded Skills  #####################\")\n",
    "    print(NeededSkills)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the paths to be used\n",
    "dPath= os.getcwd()\n",
    "LinkedInpath= \"C:\\\\Users\\\\Victor\\\\Documents\\\\LinkedIn Input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the files to be used\n",
    "fNameTest = os.path.join(LinkedInpath,\"TestCVLinkedin(31).json\")\n",
    "\n",
    "fDoc2VecModel = os.path.join(dPath,'Model/Doc2vecForSentences.model')\n",
    "fNameModelSk = os.path.join(dPath,\"Model/LogisticRegressionModelSkills.pkl\")\n",
    "fNameModelExp = os.path.join(dPath,\"Model/LogisticRegressionModelExperience.pkl\")\n",
    "fNameCatj2Id = os.path.join(dPath,\"Model/CatalogJobtoId.pkl\")\n",
    "fNameCatId2J = os.path.join(dPath,\"Model/CatalogIdtoJob.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the items from disk\n",
    "Doc2VecModel = Doc2Vec.load(fDoc2VecModel)\n",
    "lrModelExp = joblib.load(fNameModelExp)\n",
    "CatId2Job = pickle.load( open( fNameCatId2J, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Bruce Jachens\n",
      "Actual Job: Sr. Project Manager\n",
      "Job Predicted: senior project manager or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "   Category                  Skill\n",
      "0      must     project management\n",
      "1       avg      business analysis\n",
      "2       avg  requirements analysis\n",
      "3       avg               strategy\n",
      "5       avg       business process\n",
      "7       avg    agile methodologies\n",
      "8       avg     program management\n",
      "10      avg      vendor management\n",
      "13     plus                   sdlc\n",
      "15     plus            integration\n",
      "17     plus  business intelligence\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "   Category                  Skill\n",
      "4       avg       project planning\n",
      "6       avg      change management\n",
      "9       avg        team leadership\n",
      "11      avg             leadership\n",
      "12     plus        risk management\n",
      "14     plus             consulting\n",
      "16     plus        team management\n",
      "18     plus       project delivery\n",
      "19     plus   business development\n",
      "20     plus  management consulting\n",
      "21     plus     service management\n",
      "22     plus                prince2\n",
      "\n",
      "\n",
      "To levelup in this area...\n",
      "\n",
      "\n",
      "Job Predicted: director or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "Empty DataFrame\n",
      "Columns: [Category, Skill]\n",
      "Index: []\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "  Category           Skill\n",
      "0     must  windows server\n",
      "1     must        epicor 9\n"
     ]
    }
   ],
   "source": [
    "testResumes = open_file(fNameTest)\n",
    "Name=testResumes['Resume'][0]['name']\n",
    "actualJob= testResumes['Resume'][0]['job']\n",
    "\n",
    "Experience = token_separation(testResumes['Resume'][0]['summary'].lower(),splitted=False,bSentence=True,bStopwords=True)\n",
    "expEmbedding=infer_doc2vec(Doc2VecModel,[Experience])\n",
    "\n",
    "y = lrModelExp.predict(expEmbedding)#1,9TA,14,16,21,8\n",
    "\n",
    "Skills = create_arr_by_skills(testResumes['Resume'][0]['skills_endorsment'])\n",
    "SkillsTkn =  token_separation(Skills[0],bSentence=True,bStopwords=True)\n",
    "SkillEmb= infer_doc2vec(Doc2VecModel,SkillsTkn)\n",
    "\n",
    "print (\"Name: {}\".format(Name))\n",
    "print (\"Actual Job: {}\".format(actualJob))\n",
    "lqClust = getClusterQualified(y[0],dPath,SkillEmb,Doc2VecModel)\n",
    "\n",
    "print (\"\\n\\nTo levelup in this area...\\n\\n\")\n",
    "\n",
    "lqClust = getClusterQualified(y[0]+1,dPath,SkillEmb,Doc2VecModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: César Martínez\n",
      "Actual Job: Developer Sr\n",
      "summary: Cesar is a Sr.Net professional with 10 years of experience , He has developing web applications and desktop application using Microsoft technologies He has working in the full Software Development Life Cycle including Requirements Analysis, High Level Design, Detailed Design, Build, Testing, Security, Acceptance and Installation, Maintenance and Production Support carried out several .Net roles as a technical leader, lead developer and technical consultant in the TI, Government, financial, Entertainment and media sectors. As a .NET Technical Lead/Architect he also has experience on each activity of the SDLC such as requirements gathering and analysis with uses cases and user stories, OO analysis and design using severalUML diagrams, OO developing with design patterns (such as Singleton, Abstract Factory and Factory Method, Dependency Injection,Memento, MVC,MVVM), functional testing with Mercury Quality Center 9.0, Test Manager, QT Pro, unit testingand Continuous Delivery using TFS 2012 , 2010 and N-UNIT. He also has experience working and incorporating best practices and agile methodologies such as SCRUM, rup and cmmi.\n",
      "Job Predicted: project manager or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "   Category                Skill\n",
      "1       avg           leadership\n",
      "5       avg                  sql\n",
      "6       avg      team leadership\n",
      "10     plus  agile methodologies\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "   Category                         Skill\n",
      "0      must            project management\n",
      "2       avg             business analysis\n",
      "3       avg          software development\n",
      "4       avg                   integration\n",
      "7       avg         requirements analysis\n",
      "8       avg                      strategy\n",
      "9       avg  business process improvement\n",
      "11     plus             change management\n",
      "12     plus            strategic planning\n",
      "13     plus             vendor management\n",
      "14     plus              microsoft office\n",
      "\n",
      "\n",
      "To levelup in this area...\n",
      "\n",
      "\n",
      "Job Predicted: senior project manager or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "   Category                Skill\n",
      "7       avg  agile methodologies\n",
      "9       avg      team leadership\n",
      "11      avg           leadership\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "   Category                  Skill\n",
      "0      must     project management\n",
      "1       avg      business analysis\n",
      "2       avg  requirements analysis\n",
      "3       avg               strategy\n",
      "4       avg       project planning\n",
      "5       avg       business process\n",
      "6       avg      change management\n",
      "8       avg     program management\n",
      "10      avg      vendor management\n",
      "12     plus        risk management\n",
      "13     plus                   sdlc\n",
      "14     plus             consulting\n",
      "15     plus            integration\n",
      "16     plus        team management\n",
      "17     plus  business intelligence\n",
      "18     plus       project delivery\n",
      "19     plus   business development\n",
      "20     plus  management consulting\n",
      "21     plus     service management\n",
      "22     plus                prince2\n"
     ]
    }
   ],
   "source": [
    "testResumes = open_file(fNameTest)\n",
    "Name=testResumes['Resume'][1]['name']\n",
    "actualJob= testResumes['Resume'][1]['job']\n",
    "\n",
    "Experience = token_separation(testResumes['Resume'][1]['summary'].lower(),splitted=False,bSentence=True,bStopwords=True)\n",
    "expEmbedding=infer_doc2vec(Doc2VecModel,[Experience])\n",
    "\n",
    "y = lrModelExp.predict(expEmbedding)#1,9TA,14,16,21,8\n",
    "\n",
    "Skills = create_arr_by_skills(testResumes['Resume'][1]['skills_endorsment'])\n",
    "SkillsTkn =  token_separation(Skills[0],bSentence=True,bStopwords=True)\n",
    "SkillEmb= infer_doc2vec(Doc2VecModel,SkillsTkn)\n",
    "\n",
    "print (\"Name: {}\".format(Name))\n",
    "print (\"Actual Job: {}\".format(actualJob))\n",
    "print (\"summary: {}\".format(testResumes['Resume'][1]['summary']))\n",
    "lqClust = getClusterQualified(y[0],dPath,SkillEmb,Doc2VecModel)\n",
    "\n",
    "print (\"\\n\\nTo levelup in this area...\\n\\n\")\n",
    "\n",
    "lqClust = getClusterQualified(y[0]+1,dPath,SkillEmb,Doc2VecModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Guillermo Romero\n",
      "Actual Job: Android Engineer\n",
      "summary: Develop Software able to process high volumes of data and huge demand. Propose and build innovative ways in which the new technologies could help companies to increase their profit.\n",
      "Job Predicted: senior consultant or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "   Category            Skill\n",
      "0      must              sql\n",
      "1      must       javascript\n",
      "2       avg             java\n",
      "4       avg             html\n",
      "5       avg              css\n",
      "6       avg              xml\n",
      "9       avg            mysql\n",
      "11      avg  web development\n",
      "14     plus           jquery\n",
      "21     plus              jsp\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "   Category                 Skill\n",
      "3       avg  software development\n",
      "7       avg    project management\n",
      "8       avg       team leadership\n",
      "10      avg          web services\n",
      "12     plus                 scrum\n",
      "13     plus      web applications\n",
      "15     plus      microsoft office\n",
      "16     plus                  ajax\n",
      "17     plus             hibernate\n",
      "18     plus               testing\n",
      "19     plus     business analysis\n",
      "20     plus                spring\n",
      "\n",
      "\n",
      "To levelup in this area...\n",
      "\n",
      "\n",
      "Job Predicted: project leader or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "   Category            Skill\n",
      "0      must              sql\n",
      "1       avg       javascript\n",
      "3       avg             java\n",
      "5       avg              xml\n",
      "6       avg             html\n",
      "10     plus  web development\n",
      "13     plus            mysql\n",
      "16     plus              css\n",
      "17     plus           jquery\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "   Category                  Skill\n",
      "2       avg                asp.net\n",
      "4       avg             management\n",
      "7       avg   software development\n",
      "8       avg  requirements analysis\n",
      "9      plus    agile methodologies\n",
      "11     plus                  scrum\n",
      "12     plus                     c#\n",
      "14     plus           web services\n",
      "15     plus                   sdlc\n"
     ]
    }
   ],
   "source": [
    "testResumes = open_file(fNameTest)\n",
    "Name=testResumes['Resume'][2]['name']\n",
    "actualJob= testResumes['Resume'][2]['job']\n",
    "\n",
    "Experience = token_separation(testResumes['Resume'][2]['summary'].lower(),splitted=False,bSentence=True,bStopwords=True)\n",
    "expEmbedding=infer_doc2vec(Doc2VecModel,[Experience])\n",
    "\n",
    "y = lrModelExp.predict(expEmbedding)#1,9TA,14,16,21,8\n",
    "\n",
    "Skills = create_arr_by_skills(testResumes['Resume'][2]['skills_endorsment'])\n",
    "SkillsTkn =  token_separation(Skills[0],bSentence=True,bStopwords=True)\n",
    "SkillEmb= infer_doc2vec(Doc2VecModel,SkillsTkn)\n",
    "\n",
    "print (\"Name: {}\".format(Name))\n",
    "print (\"Actual Job: {}\".format(actualJob))\n",
    "print (\"summary: {}\".format(testResumes['Resume'][2]['summary']))\n",
    "lqClust = getClusterQualified(y[0],dPath,SkillEmb,Doc2VecModel)\n",
    "\n",
    "print (\"\\n\\nTo levelup in this area...\\n\\n\")\n",
    "\n",
    "lqClust = getClusterQualified(y[0]+1,dPath,SkillEmb,Doc2VecModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Meleneal Cameron\n",
      "Actual Job: Web Developer/Lead Campaign Specialist\n",
      "summary: I am a driven professional with over ten years of experience and I am proficient in data management, web development, digital marketing, and content management. I am known for my excellent interpersonal skills and my ability to multitask and meet deadlines. \n",
      "WEB DEVELOPMENT \n",
      "HTML, CSS, JavaScript, PHP\n",
      "CONTENT MANAGEMENT \n",
      "Wordpress, Joomla, Convio, Omni Update\n",
      "ESPs\n",
      "Convio, SalsaLabs, Responsys, Blackbaud\n",
      "ANALYTICS \n",
      "SEO, Web Analytics, Target Analytics, Research Point, NOZA\n",
      "DATABASE ADMINISTRATION\n",
      "SQL, Server Enterprise Manager, Blackbaud Management Console, Raiser’s Edge, Convio, iMIS, IBM AS 400, Paradox, Microsoft Access \n",
      "SOFTWARE APPLICATIONS \n",
      "Adobe Dreamweaver, Photoshop, SEO Powersuite, Crystal Reports\n",
      "Job Predicted: it consultant or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "  Category               Skill\n",
      "2      avg  project management\n",
      "5     plus                html\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "  Category                 Skill\n",
      "0     must                   sql\n",
      "1      avg            javascript\n",
      "3      avg                  java\n",
      "4      avg                 mysql\n",
      "6     plus  software development\n",
      "7     plus      spring framework\n",
      "8     plus                jquery\n",
      "9     plus                   css\n",
      "\n",
      "\n",
      "To levelup in this area...\n",
      "\n",
      "\n",
      "Job Predicted: senior consultant or equivalent\n",
      "\n",
      "##################  Skills Qualified  #####################\n",
      "   Category               Skill\n",
      "4       avg                html\n",
      "7       avg  project management\n",
      "11      avg     web development\n",
      "\n",
      "##################  Nedded Skills  #####################\n",
      "   Category                 Skill\n",
      "0      must                   sql\n",
      "1      must            javascript\n",
      "2       avg                  java\n",
      "3       avg  software development\n",
      "5       avg                   css\n",
      "6       avg                   xml\n",
      "8       avg       team leadership\n",
      "9       avg                 mysql\n",
      "10      avg          web services\n",
      "12     plus                 scrum\n",
      "13     plus      web applications\n",
      "14     plus                jquery\n",
      "15     plus      microsoft office\n",
      "16     plus                  ajax\n",
      "17     plus             hibernate\n",
      "18     plus               testing\n",
      "19     plus     business analysis\n",
      "20     plus                spring\n",
      "21     plus                   jsp\n"
     ]
    }
   ],
   "source": [
    "testResumes = open_file(fNameTest)\n",
    "Name=testResumes['Resume'][3]['name']\n",
    "actualJob= testResumes['Resume'][3]['job']\n",
    "\n",
    "Experience = token_separation(testResumes['Resume'][3]['summary'].lower(),splitted=False,bSentence=True,bStopwords=True)\n",
    "expEmbedding=infer_doc2vec(Doc2VecModel,[Experience])\n",
    "\n",
    "y = lrModelExp.predict(expEmbedding)#1,9TA,14,16,21,8\n",
    "\n",
    "Skills = create_arr_by_skills(testResumes['Resume'][3]['skills_endorsment'])\n",
    "SkillsTkn =  token_separation(Skills[0],bSentence=True,bStopwords=True)\n",
    "SkillEmb= infer_doc2vec(Doc2VecModel,SkillsTkn)\n",
    "\n",
    "print (\"Name: {}\".format(Name))\n",
    "print (\"Actual Job: {}\".format(actualJob))\n",
    "print (\"summary: {}\".format(testResumes['Resume'][3]['summary'].replace (\"\\\\n\",\"\\n\")))\n",
    "lqClust = getClusterQualified(y[0],dPath,SkillEmb,Doc2VecModel)\n",
    "\n",
    "print (\"\\n\\nTo levelup in this area...\\n\\n\")\n",
    "\n",
    "lqClust = getClusterQualified(y[0]+1,dPath,SkillEmb,Doc2VecModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
